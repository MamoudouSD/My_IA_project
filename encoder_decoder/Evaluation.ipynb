{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# DIANI Mamoudou Sékou\n",
    "#\n",
    "# Avril 2022\n",
    "#==========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import backend as K\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "\n",
    "# Configuration des GPUs et CPUs\n",
    "config = tf.compat.v1.ConfigProto(device_count={'GPU': 2, 'CPU': 4})\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modéle (autoencodeur) sauvegardé dans la section 1 via 1_Modele.py\n",
    "model_path = \"Model.hdf5\"\n",
    "autoencoder = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration des chemins vers les fichiers cibles\n",
    "mainDataPath = \"vache_elephant/\"\n",
    "datapath = mainDataPath + \"test\"\n",
    "\n",
    "# Le nombre des images de test à évaluer\n",
    "number_images = 400\n",
    "number_images_class_0 = 200 \n",
    "number_images_class_1 = 200 \n",
    "\n",
    "# Les étiquettes des images\n",
    "labels = np.array([0] * number_images_class_0 +\n",
    "                  [1] * number_images_class_1)\n",
    "\n",
    "# La taille des images\n",
    "image_scale = 96\n",
    "\n",
    "# La couleur des images\n",
    "images_color_mode = \"rgb\"  # grayscale ou rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des images test\n",
    "data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "generator = data_generator.flow_from_directory(\n",
    "    datapath, # Place des images d'entrainement\n",
    "    color_mode=images_color_mode, # couleur des images\n",
    "    target_size=(image_scale, image_scale),# taille des images\n",
    "    batch_size= number_images, # nombre d'images total à charger en mémoire\n",
    "    class_mode=None,\n",
    "    shuffle=False) # pas besoin de bouleverser les images\n",
    "\n",
    "x = generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruire les images tests en utilisant l'autoencodeur entrainé dans la première étape.\n",
    "prediction = autoencoder.predict(x)\n",
    "def show_image(x):\n",
    "    plt.imshow(np.clip(x + 0.5, 0, 1))\n",
    "def afficheImg(imgO, imgP, classe):\n",
    "  plt.subplot(1,3,1)\n",
    "  plt.title(\"Original classe \"+classe)\n",
    "  plt.axis('off')\n",
    "  show_image(imgO)\n",
    "\n",
    "  plt.subplot(1,3,3)\n",
    "  plt.title(\"Reconstructed classe \"+classe)\n",
    "  plt.axis('off')\n",
    "  show_image(imgP)\n",
    "  plt.show()\n",
    "\n",
    "afficheImg(x[0], prediction[0], \"0\")\n",
    "afficheImg(x[200], prediction[200], \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition d'un modèle \"encoder\" qui est formé que de la partie encodeur de l'autoencodeur\n",
    "input_layer_index = 0 # l'indice de la première couche de l'encodeur\n",
    "output_layer_index = 9 # l'indice de la dernière couche de l'encodeur \n",
    "encoder = Model(autoencoder.layers[0].input, autoencoder.layers[9].output)\n",
    "embedding = encoder.predict(x)\n",
    "\n",
    "l=[]\n",
    "for i in range(len(embedding)):\n",
    "  a=embedding[i].flatten()\n",
    "  l.append(a)\n",
    "embedding=l\n",
    "\n",
    "# Normalisation de emdedding\n",
    "scaler = StandardScaler()\n",
    "embedding = scaler.fit_transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquation un SVM Linéaire sur les images originales \n",
    "# Entrainement du modèle avec le cross-validation\n",
    "\n",
    "y=[]\n",
    "for i in range(number_images_class_0):\n",
    "  y.append(0)\n",
    "\n",
    "for i in range(number_images_class_1):\n",
    "  y.append(1)\n",
    "\n",
    "nsamples, nx, ny, nz = x.shape\n",
    "d2_x = x.reshape((nsamples,nx*ny*nz))\n",
    "lin_svc = svm.LinearSVC() \n",
    "\n",
    "cv_results = cross_validate(lin_svc, d2_x, y)\n",
    "print(\"l'accuracy: \", cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquation un SVC Linéaire sur le flattened embedding normalisé\n",
    "# Entrainer le modèle avec le cross-validation\n",
    "\n",
    "nsamples, nx = embedding.shape\n",
    "d2_x = embedding.reshape((nsamples,nx))\n",
    "lin_svc = svm.LinearSVC()\n",
    "\n",
    "cv_results = cross_validate(lin_svc, d2_x, y)\n",
    "print(\"l'accuracy: \", cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquation d'un TSNE sur le flattened embedding\n",
    "# affichage des 2D features dans un scatter plot avec des couleurs differentes\n",
    "# ***********************************************\n",
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(embedding)\n",
    "\n",
    "a= X_embedded[0:200]\n",
    "b= X_embedded[200:400]\n",
    "x1=[]\n",
    "y1=[]\n",
    "x2=[]\n",
    "y2=[]\n",
    "for i in range (len(a)):\n",
    "  x1.append(a[i][0])\n",
    "  y1.append(a[i][1])\n",
    "\n",
    "for i in range (len(b)):\n",
    "  x2.append(b[i][0])\n",
    "  y2.append(b[i][1])\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize':(10,8)})\n",
    "plt.scatter(x1, y1, label=f'classe 0')\n",
    "plt.scatter(x2, x2, label=f'classe 1')\n",
    "\n",
    "# Plot\n",
    "plt.title('Scatterplot and Correlations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
