{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# DIANI Mamoudou Sékou\n",
    "#\n",
    "# Avril 2022\n",
    "#==========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization, UpSampling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "\n",
    "# Configuration des GPUs et CPUs\n",
    "config = tf.compat.v1.ConfigProto(device_count={'GPU': 2, 'CPU': 4})\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration des chemins vers les fichiers cibles\n",
    "\n",
    "# Le dossier principal qui contient les données\n",
    "mainDataPath = \"vache_elephant/\"\n",
    "\n",
    "# Le dossier contenant les images d'entrainement\n",
    "trainPath = mainDataPath + \"entrainement\"\n",
    "\n",
    "# Le dossier contenant les images de validation\n",
    "validationPath = mainDataPath + \"validation\"\n",
    "\n",
    "# Le nom du fichier du modèle à sauvegarder\n",
    "model_path = \"Model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration des variable \n",
    "\n",
    "# Le nombre d'images d'entrainement\n",
    "training_ds_size = 1992  \n",
    "validation_ds_size = 408  \n",
    "\n",
    "\n",
    "# Configuration des  images\n",
    "image_scale = 96 \n",
    "image_channels = 3 \n",
    "images_color_mode = \"rgb\" \n",
    "image_shape = (image_scale, image_scale,\n",
    "               image_channels)  \n",
    "\n",
    "# Configuration des paramètres d'entrainement\n",
    "fit_batch_size = 70  \n",
    "fit_epochs = 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CHARGEMENT DES IMAGES===========\n",
    "# ==========================================\n",
    "\n",
    "# training_data_generator: charge les données d'entrainement\n",
    "# Les images sont normalisées (leurs pixels divisées par 255)\n",
    "training_data_generator = ImageDataGenerator(rescale=1. / 255, validation_split=0.17)\n",
    "\n",
    "# validation_data_generator: charge les données de validation \n",
    "# Les images sont normalisées (leurs pixels divisées par 255)\n",
    "validation_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# training_generator: indique la méthode de chargement des données d'entrainement\n",
    "training_generator = training_data_generator.flow_from_directory(\n",
    "    trainPath, \n",
    "    color_mode =images_color_mode, \n",
    "    target_size=(image_scale, image_scale),\n",
    "    batch_size = training_ds_size, \n",
    "    class_mode =\"input\", \n",
    "    subset='training') \n",
    "\n",
    "# validation_generatory: indique la méthode de chargement des données de validation\n",
    "validation_generator = training_data_generator.flow_from_directory(\n",
    "    trainPath, \n",
    "    color_mode =images_color_mode, \n",
    "    target_size=(image_scale, image_scale),\n",
    "    batch_size = validation_ds_size, \n",
    "    class_mode =\"input\", \n",
    "    subset='validation') \n",
    "\n",
    "# On charge les données d'entrainement \n",
    "(x_train, _) = training_generator.next()\n",
    "# On charge les données de validation \n",
    "(x_val, _) = validation_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couche d'entrée\n",
    "input_layer = Input(shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Encodage\n",
    "def encoder(input):\n",
    "    x = Conv2D(512, (3, 3), padding='same')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "# Partie de décodage (qui reconstruit les images à partir de leur embedding ou la sortie de l'encodeur)\n",
    "def decoder(encoded):\n",
    "    x = Conv2D(128, (3, 3), padding='same')(encoded)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(image_channels, (3, 3), padding='same')(x)\n",
    "    decoded = Activation('relu')(x)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "# Déclaration du modèle\n",
    "model = Model(input_layer, decoder(encoder(input_layer)))\n",
    "\n",
    "# Affichage des paramétres du modèle\n",
    "model.summary()\n",
    "\n",
    "# Compilation du modèle :\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Savegarder le modèle avec le minimum loss sur les données de validation (monitor='val_loss')\n",
    "modelcheckpoint = ModelCheckpoint(filepath=model_path,\n",
    "                                  monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# entrainement du modèle\n",
    "autoencoder = model.fit(x_train, x_train,\n",
    "                       epochs=fit_epochs, # nombre d'epochs\n",
    "                       batch_size=fit_batch_size, # nombre d'images entrainées ensemble\n",
    "                       verbose=1, # mets cette valeur à 0, si vous voulez ne pas afficher les détails d'entrainement\n",
    "                       callbacks=[modelcheckpoint], # les fonctions à appeler à la fin de chaque epoch (dans ce cas modelcheckpoint: qui sauvegarde le modèle)\n",
    "                       shuffle=False, # On ne boulverse pas les données\n",
    "                       validation_data=(x_val, x_val)) # données de validation\n",
    "\n",
    "\n",
    "plt.plot(autoencoder.history['loss'])\n",
    "plt.plot(autoencoder.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "fig = plt.gcf()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
