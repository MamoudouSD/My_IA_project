{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# DIANI Mamoudou Sékou\n",
    "#\n",
    "# Juin 2022\n",
    "#===========================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization, UpSampling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Configuration des GPUs et CPUs\n",
    "config = tf.compat.v1.ConfigProto(device_count={'GPU': 2, 'CPU': 4})\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration des chemins vers les fichiers cibles\n",
    "\n",
    "# Le dossier principal qui contient les donnees\n",
    "mainDataPath = \"donnees2/\"\n",
    "\n",
    "# Le dossier contenant les images d'entrainement\n",
    "trainPath = mainDataPath + \"entrainement\"\n",
    "\n",
    "# Le dossier contenant les images de validation\n",
    "validationPath = mainDataPath + \"validation\"\n",
    "\n",
    "# Le dossier contenant les images de test\n",
    "testPath = mainDataPath + \"test\"\n",
    "\n",
    "# Le nom du fichier du modele a sauvegarder\n",
    "modelsPath = \"Model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration des variable \n",
    "training_batch_size = 18000  \n",
    "validation_batch_size = 6000  \n",
    "\n",
    "# Configuration des  images \n",
    "image_scale = 100 # la taille des images\n",
    "image_channels = 3  # le nombre de canaux de couleurs \n",
    "images_color_mode = \"rgb\"  \n",
    "image_shape = (image_scale, image_scale, image_channels) # la forme des images d'entrees\n",
    "\n",
    "# Configuration des parametres d'entrainement\n",
    "fit_batch_size = 180 # le nombre d'images entrainees ensemble: un batch\n",
    "fit_epochs = 70 # Le nombre d'epoques \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# ==========CHARGEMENT DES IMAGES===========\n",
    "# ==========================================\n",
    "# Charge les donnees d'entrainement en memoire\n",
    "training_data_generator = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True, validation_split=0.25)\n",
    "\n",
    "# Charge les donnees de validation en memoire\n",
    "validation_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# training_generator: indique la methode de chargement des donnees d'entrainement\n",
    "training_generator = training_data_generator.flow_from_directory(\n",
    "    trainPath, # Place des images d'entrainement\n",
    "    color_mode=images_color_mode, # couleur des images\n",
    "    target_size=(image_scale, image_scale),# taille des images\n",
    "    batch_size=training_batch_size, # nombre d'images a entrainer \n",
    "    class_mode=\"categorical\", # classement\n",
    "    shuffle=True, \n",
    "    subset='training') # on \"brasse\" (shuffle) les donnees pour prevenir le surapprentissage\n",
    "\n",
    "# validation_generator: indique la methode de chargement des donnees de validation\n",
    "validation_generator = training_data_generator.flow_from_directory(\n",
    "    trainPath, # Place des images de validation\n",
    "    color_mode=images_color_mode, # couleur des images\n",
    "    target_size=(image_scale, image_scale),  # taille des images\n",
    "    batch_size=validation_batch_size,  # nombre d'images a valider\n",
    "    class_mode=\"categorical\",  # classement \n",
    "    shuffle=True, \n",
    "    subset='validation') # on \"brasse\" (shuffle) les donnees pour prevenir le surapprentissage\n",
    "\n",
    "\n",
    "# On charge les donnees d'entrainement et de validation\n",
    "(x_train, y_train) = training_generator.next()\n",
    "(x_val, y_val) = validation_generator.next()\n",
    "\n",
    "# On Normalise les images en les divisant par la plus grande pixel dans les images (generalement c'est 255)\n",
    "max_value = float(x_train.max())\n",
    "x_train = x_train.astype('float32') / max_value\n",
    "x_val = x_val.astype('float32') / max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couche d'entree\n",
    "input_layer = Input(shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partie feature extraction \n",
    "def feature_extraction(input):    \n",
    "    x = Conv2D(100, (3, 3), padding='same')(input) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(100, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same', strides=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same', strides=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same', strides=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same', strides=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same', strides=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x) \n",
    "    x = Activation(\"relu\")(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same',strides=(2,2))(x)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "# Partie completement connect�e (Fully Connected Layer)\n",
    "def fully_connected(encoded):\n",
    "    x = Flatten(input_shape=image_shape)(encoded)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x= Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x= Dropout(0.5)(x)\n",
    "    x = Dense(6)(x)\n",
    "    sortie = Activation('softmax')(x)\n",
    "    return sortie\n",
    "\n",
    "# Declaration du modele:\n",
    "model = Model(img_input, fully_connected(feature_extraction(input_layer)))\n",
    "\n",
    "# Affichage des parametres du modele\n",
    "model.summary()\n",
    "# Compilation du modele en definissant la fonction de perte, l'optimisateur et la valeur afficher durant l'entrainement\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle ayant le meilleur val_accuracy pendant l'entraînement dans Model.hdf5. \n",
    "modelcheckpoint = ModelCheckpoint(filepath=modelsPath,\n",
    "                                  monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "# entrainement du modele\n",
    "classifier = model.fit(x_train, y_train,\n",
    "                       epochs=fit_epochs, # nombre d'�poques\n",
    "                       batch_size=fit_batch_size, # nombre d'images entrain�es ensemble\n",
    "                       validation_data=(x_val, y_val), # donn�es de validation\n",
    "                       verbose=1, # mets cette valeur � 0, si vous voulez ne pas afficher les d�tails d'entrainement\n",
    "                       callbacks=[modelcheckpoint], # les fonctions � appeler � la fin de chaque �poque (dans ce cas modelcheckpoint: qui sauvegarde le mod�le)\n",
    "                       shuffle=True)# shuffle les images\n",
    "\n",
    "# ==========================================\n",
    "# ========AFFICHAGE DES RESULTATS===========\n",
    "# ==========================================\n",
    "\n",
    "# Plot accuracy over epochs (precision par epoque)\n",
    "print(classifier.history.keys())\n",
    "plt.plot(classifier.history['accuracy'])\n",
    "plt.plot(classifier.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "fig = plt.gcf()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage de la courbe de perte (loss curve)\n",
    "print(classifier.history.keys())\n",
    "plt.plot(classifier.history['loss'])\n",
    "plt.plot(classifier.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "fig = plt.gcf()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
