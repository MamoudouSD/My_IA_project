{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================================================\n",
        "# DIANI Mamoudou Sékou\n",
        "#\n",
        "# Juin 2023\n",
        "#==========================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import ast\n",
        "from scipy import stats\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Conv2D, MaxPooling2D, Add, MaxPooling1D, Input, BatchNormalization, UpSampling2D, Activation, Dropout, Flatten, Dense, Lambda, Concatenate, GlobalAveragePooling1D\n",
        "from keras import backend\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "from keras.models import load_model\n",
        "from keras import Model\n",
        "\n",
        "# Importation des bibliothèques nécessaires pour le traitement d'images avec TensorFlow et Keras\n",
        "import tensorflow as tf\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMyGFlAGTGlx"
      },
      "outputs": [],
      "source": [
        "# Cette fonction charge les données brutes à partir des fichiers ECG en utilisant la bibliothèque wfdb.\n",
        "# Elle prend en parametre le dataFrame contenant les informations sur les fichiers, le taux d'échantillonnage des signaux\n",
        "# Le chemin vers le répertoire contenant les fichiers et renvoie un tableau contenant les signaux bruts.\n",
        "def load_raw_data(df, sampling_rate, path):\n",
        "    if sampling_rate == 100:\n",
        "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
        "    else:\n",
        "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
        "    data = np.array([signal for signal, meta in data])\n",
        "    return data\n",
        "\n",
        "# Chemin vers le répertoire contenant les fichiers\n",
        "path = '/Users/mamoudousdiani/Documents/UQAM/projet_master/Base_de_donnee/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3/'\n",
        "\n",
        "# Taux d'échantillonnage\n",
        "sampling_rate=100\n",
        "\n",
        "# Chargement et convertion des données d'annotation\n",
        "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
        "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "# # Chargement des données brutes des signaux\n",
        "X = load_raw_data(Y, sampling_rate, path)\n",
        "\n",
        "# Chargement de scp_statements.csv pour l'agrégation diagnostique\n",
        "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
        "agg_df = agg_df[agg_df.diagnostic == 1]\n",
        "\n",
        "\n",
        "# Cette fonction agrège les diagnostics en utilisant le fichier scp_statements.csv\n",
        "# Elle prend comme parametre un dictionnaire contenant les codes de diagnostic\n",
        "# Et renvoie la liste des classes diagnostiques agrégées\n",
        "# La fonction parcourt les clés du dictionnaire (y_dic) et vérifie si chaque \n",
        "# clé existe dans le fichier scp_statements.csv (représenté par le DataFrame agg_df).\n",
        "# Si la clé existe, la fonction ajoute la classe diagnostique correspondante à la liste temporaire.\n",
        "# Enfin, la fonction utilise un ensemble (set) pour éliminer les doublons, puis convertit cet ensemble en liste et la renvoie.\n",
        "def aggregate_diagnostic(y_dic):\n",
        "    tmp = []\n",
        "    for key in y_dic.keys():\n",
        "        if key in agg_df.index:\n",
        "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
        "    return list(set(tmp))\n",
        "\n",
        "# Appliquation de la superclasse diagnostique\n",
        "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
        "\n",
        "# Séparation des données en ensembles d'entraînement, de validation et de test\n",
        "test_fold = 9\n",
        "# Train\n",
        "X_train1 = X[np.where(Y.strat_fold < test_fold)]\n",
        "y_train1 = Y[(Y.strat_fold < test_fold)].diagnostic_superclass\n",
        "# validation\n",
        "X_val1 = X[np.where(Y.strat_fold == test_fold)]\n",
        "y_val1 = Y[Y.strat_fold == test_fold].diagnostic_superclass\n",
        "# Test\n",
        "X_test1 = X[np.where(Y.strat_fold > test_fold)]\n",
        "y_test1 = Y[Y.strat_fold > test_fold].diagnostic_superclass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1Oo9yQ2THqF"
      },
      "outputs": [],
      "source": [
        "# Cette fonction convertit les codes de diagnostic en un tableau de classe diagnostique.\n",
        "# Elle prend en paramètre X un dictionnaire contenant les codes de diagnostic pour un enregistrement ECG\n",
        "# et renvoie un Tableau de classe diagnostique encodé, la liste des indices des diagnostics valides.\n",
        "# et la liste des indices des diagnostics non valides\n",
        "def convY(x):\n",
        "    a=x.keys()\n",
        "    d=[]\n",
        "    listeV=[]\n",
        "    listeNV=[]\n",
        "    lv=0\n",
        "    N=0\n",
        "    M=0\n",
        "    S=0\n",
        "    C=0\n",
        "    H=0\n",
        "    bof=0\n",
        "    for i in range(len(a)):\n",
        "        if 'NORM' in x[a[i]]:\n",
        "            d.append([1, 0, 0, 0, 0])\n",
        "            #listeV.append(i)\n",
        "            N=N+1\n",
        "        elif 'MI' in x[a[i]]:\n",
        "            d.append([0, 1, 0, 0, 0])\n",
        "            listeV.append(i)\n",
        "            M=M+1\n",
        "        elif 'STTC' in x[a[i]]:\n",
        "            d.append([0, 0, 1, 0, 0])\n",
        "            listeV.append(i)\n",
        "            S=S+1\n",
        "        elif 'CD' in x[a[i]]:\n",
        "            d.append([0, 0, 0, 1, 0])\n",
        "            listeV.append(i)\n",
        "            C=C+1\n",
        "        elif 'HYP' in x[a[i]]:\n",
        "            d.append([0, 0, 0, 0, 1])\n",
        "            listeV.append(i)\n",
        "            H=H+1\n",
        "        else:\n",
        "            d.append([0, 0, 0, 0, 0])\n",
        "            listeNV.append(i)\n",
        "            bof=bof+1\n",
        "        lv=lv+1\n",
        "\n",
        "    d= np.array(d)\n",
        "    print(N,M,S,C,H,bof)\n",
        "    return d, listeV, listeNV\n",
        "\n",
        "\n",
        "# Cette fonction calcule la moyenne et l'écart type des valeurs dans une liste tridimensionnelle\n",
        "# Elle prend en paramètre une liste tridimensionnelle contenant les valeurs\n",
        "# Elle retourne la moyenne et l'ecart type des valeurs\n",
        "def calcul(X_train):\n",
        "    a=0\n",
        "    nb=0\n",
        "    for i in range(len(X_train)):\n",
        "        for j in range(len(X_train[i])):\n",
        "            for k in range(len(X_train[i][j])):\n",
        "                a=a+X_train[i][j][k]\n",
        "                nb=nb+1\n",
        "    moy=a/nb\n",
        "    b=0\n",
        "    for i in range(len(X_train)):\n",
        "        for j in range(len(X_train[i])):\n",
        "            for k in range(len(X_train[i][j])):\n",
        "                b=b+((X_train[i][j][k]-moy)**2)\n",
        "    ecT=sqrt(b/nb)\n",
        "    return moy, ecT\n",
        "\n",
        "\n",
        "# Cette fonction normalise une liste tridimensionnelle en utilisant la moyenne et l'écart type.\n",
        "# Elle prend en paramètre une liste tridimensionnelle à normaliser, la moyenne des valeurs utilisée pour la normalisation\n",
        "# l'ecart type des valeurs utilisé pour la normalisation.\n",
        "# Elle retourne une liste tridimensionnelle normalisée.\n",
        "def normalisation(l,moy, ecT):\n",
        "    for i in range(len(l)):\n",
        "        for j in range(len(l[i])):\n",
        "            for k in range(len(l[i][j])):\n",
        "                l[i][j][k] = (l[i][j][k]-moy)/(ecT)\n",
        "    return l\n",
        "\n",
        "\n",
        "# Cette fonction supprime les éléments non valides (pas de classe) d'une liste \n",
        "# en utilisant la liste des indices des diagnostics non valides.\n",
        "# Elle prend en paramètre X_train et y_train les listes de signaux et de leures classes \n",
        "# lnv la liste contenant les indices des éléments non valides\n",
        "# Elle retourne les liste contenant les éléments valides correspondant aux indices fournis\n",
        "def dataConcr(X_train, y_train, lnv):\n",
        "    dataX=[]\n",
        "    dataY=[]\n",
        "    for i in range(len (X_train)):\n",
        "        if i not in lnv:\n",
        "            dataX.append(X_train[i])\n",
        "            dataY.append(y_train[i])\n",
        "\n",
        "    return (stats.zscore(np.array(dataX)), np.array(dataY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXdPFXNUTKJs"
      },
      "outputs": [],
      "source": [
        "# Convertir les labels de la classe en vecteurs binaires\n",
        "y_train, lv_train, lnv_train = convY(y_train1)\n",
        "y_val, lv_val, lnv_val=convY(y_val1)\n",
        "y_test, lv_test, lnv_test=convY(y_test1)\n",
        "\n",
        "# Traitement des données d'entraînement\n",
        "X_train, y_train=dataConcr(X_train1, y_train, lnv_train)\n",
        "X_val, y_val=dataConcr(X_val1, y_val, lnv_val)\n",
        "X_test, y_test=dataConcr(X_test1, y_test, lnv_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer la forme des données d'entrée\n",
        "dataShape = (len(X_train[0]), len(X_train[0][0]))\n",
        "# Créer un objet d'entrée pour le modèle avec la forme calculée\n",
        "img_input = Input(shape=dataShape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zOPBhKPTnNm"
      },
      "outputs": [],
      "source": [
        "# Creation des fonction necessaire a l'architecture\n",
        "def part1(X, kernelSize, filtre1, filtre2, filtre3, s=2):\n",
        "    X1 = Conv1D(filters=filtre1, kernel_size=1, strides=s, padding='valid')(X)\n",
        "    X1 = BatchNormalization()(X1)\n",
        "    X1 = Activation('relu')(X1)\n",
        "\n",
        "    X1 = Conv1D(filters=filtre2, kernel_size=kernelSize, strides=1, padding='same')(X1)\n",
        "    X1 = BatchNormalization()(X1)\n",
        "    X1 = Activation('relu')(X1)\n",
        "\n",
        "    X1 = Conv1D(filters=filtre3, kernel_size=1, strides=1, padding='valid')(X1)\n",
        "    X1 = BatchNormalization()(X1)\n",
        "\n",
        "    X_shortcut = Conv1D(filters=filtre3, kernel_size=1, strides=s, padding='valid')(X)\n",
        "    X_shortcut = BatchNormalization()(X_shortcut)\n",
        "\n",
        "    X1 = Add()([X1, X_shortcut])\n",
        "    X1 = Activation('relu')(X1)\n",
        "\n",
        "    return X1\n",
        "\n",
        "def part2(X_input, kernelSize, filtre1, filtre2, filtre3):\n",
        "    X1 = Conv1D(filters=filtre1, kernel_size=1, strides=1, padding='valid')(X_input)\n",
        "    X1 = BatchNormalization()(X1)\n",
        "    X1 = Activation('relu')(X1)\n",
        "\n",
        "    X1 = Conv1D(filters=filtre2, kernel_size=kernelSize, strides=1, padding='same')(X1)\n",
        "    X1 = BatchNormalization()(X1)\n",
        "    X1 = Activation('relu')(X1)\n",
        "\n",
        "    X1 = Conv1D(filters=filtre3, kernel_size=1, strides=1, padding='valid')(X1)\n",
        "    X1 = BatchNormalization()(X1)\n",
        "\n",
        "    X1 = Add()([X1, X_input])\n",
        "    X1 = Activation('relu')(X1)\n",
        "    return X1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX4hJfXNT1L5",
        "outputId": "2e74507f-9dda-470e-df15-048ba2135501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1000, 12)]   0           []                               \n",
            "                                                                                                  \n",
            " zero_padding1d (ZeroPadding1D)  (None, 1006, 12)    0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 500, 64)      5440        ['zero_padding1d[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 500, 64)     256         ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 500, 64)      0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 249, 64)      0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 249, 64)      4160        ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 249, 64)     256         ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 249, 64)      0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 249, 64)      12352       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 249, 64)     256         ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 249, 64)      0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 249, 256)     16640       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 249, 256)     16640       ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 249, 256)    1024        ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 249, 256)    1024        ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 249, 256)     0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 249, 256)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 249, 64)      16448       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 249, 64)     256         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 249, 64)      0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 249, 64)      12352       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 249, 64)     256         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 249, 64)      0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 249, 256)     16640       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 249, 256)    1024        ['conv1d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 249, 256)     0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 249, 256)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 249, 64)      16448       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 249, 64)     256         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 249, 64)      0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 249, 64)      12352       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 249, 64)     256         ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 249, 64)      0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 249, 256)     16640       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 249, 256)    1024        ['conv1d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 249, 256)     0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 249, 256)     0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 125, 128)     32896       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 125, 128)    512         ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 125, 128)     0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 125, 128)     49280       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 125, 128)    512         ['conv1d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 125, 128)     0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 125, 512)     66048       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 125, 512)     131584      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 125, 512)    2048        ['conv1d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 125, 512)    2048        ['conv1d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 125, 512)     0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 125, 512)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 125, 128)     65664       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 125, 128)    512         ['conv1d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 125, 128)     0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 125, 128)     49280       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 125, 128)    512         ['conv1d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 125, 128)     0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 125, 512)     66048       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 125, 512)    2048        ['conv1d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 125, 512)     0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 125, 512)     0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 125, 128)     65664       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 125, 128)    512         ['conv1d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 125, 128)     0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 125, 128)     49280       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 125, 128)    512         ['conv1d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 125, 128)     0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 125, 512)     66048       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 125, 512)    2048        ['conv1d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 125, 512)     0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 125, 512)     0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)             (None, 125, 128)     65664       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 125, 128)    512         ['conv1d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 125, 128)     0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 125, 128)     49280       ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 125, 128)    512         ['conv1d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 125, 128)     0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 125, 512)     66048       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 125, 512)    2048        ['conv1d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 125, 512)     0           ['batch_normalization_23[0][0]', \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 125, 512)     0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_24 (Conv1D)             (None, 63, 256)      131328      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 63, 256)     1024        ['conv1d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 63, 256)      0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 63, 256)      196864      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 63, 256)     1024        ['conv1d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 63, 256)      0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 63, 1024)     263168      ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 63, 1024)     525312      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 63, 1024)    4096        ['conv1d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 63, 1024)    4096        ['conv1d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 63, 1024)     0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 63, 1024)     0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 63, 256)      262400      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 63, 256)     1024        ['conv1d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 63, 256)      0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 63, 256)      196864      ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 63, 256)     1024        ['conv1d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 63, 256)      0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 63, 1024)     263168      ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 63, 1024)    4096        ['conv1d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 63, 1024)     0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 63, 1024)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 63, 256)      262400      ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 63, 256)     1024        ['conv1d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 63, 256)      0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 63, 256)      196864      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 63, 256)     1024        ['conv1d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 63, 256)      0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 63, 1024)     263168      ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 63, 1024)    4096        ['conv1d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 63, 1024)     0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 63, 1024)     0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_34 (Conv1D)             (None, 63, 256)      262400      ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 63, 256)     1024        ['conv1d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 63, 256)      0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 63, 256)      196864      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 63, 256)     1024        ['conv1d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 63, 256)      0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 63, 1024)     263168      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 63, 1024)    4096        ['conv1d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 63, 1024)     0           ['batch_normalization_36[0][0]', \n",
            "                                                                  'activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 63, 1024)     0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 63, 256)      262400      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 63, 256)     1024        ['conv1d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 63, 256)      0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 63, 256)      196864      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 63, 256)     1024        ['conv1d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 63, 256)      0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 63, 1024)     263168      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 63, 1024)    4096        ['conv1d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 63, 1024)     0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 63, 1024)     0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 63, 256)      262400      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 63, 256)     1024        ['conv1d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 63, 256)      0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 63, 256)      196864      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 63, 256)     1024        ['conv1d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 63, 256)      0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 63, 1024)     263168      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 63, 1024)    4096        ['conv1d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 63, 1024)     0           ['batch_normalization_42[0][0]', \n",
            "                                                                  'activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 63, 1024)     0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 32, 512)      524800      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 32, 512)     2048        ['conv1d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 32, 512)      0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_44 (Conv1D)             (None, 32, 512)      786944      ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 32, 512)     2048        ['conv1d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 32, 512)      0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_45 (Conv1D)             (None, 32, 2048)     1050624     ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_46 (Conv1D)             (None, 32, 2048)     2099200     ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 32, 2048)    8192        ['conv1d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 32, 2048)    8192        ['conv1d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 32, 2048)     0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 32, 2048)     0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_47 (Conv1D)             (None, 32, 512)      1049088     ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 32, 512)     2048        ['conv1d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 32, 512)      0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_48 (Conv1D)             (None, 32, 512)      786944      ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 32, 512)     2048        ['conv1d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 32, 512)      0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)             (None, 32, 2048)     1050624     ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 32, 2048)    8192        ['conv1d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 32, 2048)     0           ['batch_normalization_49[0][0]', \n",
            "                                                                  'activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 32, 2048)     0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)             (None, 32, 512)      1049088     ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 32, 512)     2048        ['conv1d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 32, 512)      0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)             (None, 32, 512)      786944      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 32, 512)     2048        ['conv1d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 32, 512)      0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_52 (Conv1D)             (None, 32, 2048)     1050624     ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 32, 2048)    8192        ['conv1d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 32, 2048)     0           ['batch_normalization_52[0][0]', \n",
            "                                                                  'activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 32, 2048)     0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 65536)        0           ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          16777472    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 256)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          32896       ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 128)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2)            258         ['activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 2)            0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,849,474\n",
            "Trainable params: 32,796,354\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Création d'une architecture basée sur Resnet50\n",
        "# pour l'extraction des caractéristiques à partir de séquences temporelles 1D.\n",
        "def feature_extraction(input):\n",
        "    X = ZeroPadding1D(3)(input)\n",
        "\n",
        "    X = Conv1D(64, 7, strides=2)(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling1D(pool_size=3, strides=2)(X)\n",
        "\n",
        "    X = part1(X, 3, 64, 64, 256, s=1)\n",
        "    X = part2(X, 3, 64, 64, 256)\n",
        "    X = part2(X, 3, 64, 64, 256)\n",
        "\n",
        "    X = part1(X, 3, 128, 128, 512, s=2)\n",
        "    X = part2(X, 3, 128, 128, 512)\n",
        "    X = part2(X, 3, 128, 128, 512)\n",
        "    X = part2(X, 3, 128, 128, 512)\n",
        "\n",
        "    X = part1(X, 3, 256, 256, 1024, s=2)\n",
        "    X = part2(X, 3, 256, 256, 1024)\n",
        "    X = part2(X, 3, 256, 256, 1024)\n",
        "    X = part2(X, 3, 256, 256, 1024)\n",
        "    X = part2(X, 3, 256, 256, 1024)\n",
        "    X = part2(X, 3, 256, 256, 1024)\n",
        "\n",
        "    X = part1(X, 3, 512, 512, 2048, s=2)\n",
        "    X = part2(X, 3, 512, 512, 2048)\n",
        "    encoded = part2(X, 3, 512, 512, 2048)\n",
        "\n",
        "    return (encoded)\n",
        "\n",
        "\n",
        "# Partie completement connectee (Fully Connected Layer) pour la classification multiclasse.\n",
        "def fully_connected(encoded):\n",
        "    x = Flatten()(encoded)\n",
        "    x = Dense(256)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Dense(128)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Dense(2)(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Declaration du modele:\n",
        "model = Model(img_input, fully_connected(feature_extraction(img_input)))\n",
        "\n",
        "# Affichage des parametres du modele\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6lYdcR_LWrUU",
        "outputId": "ef6508c0-6384-41d1-f3ab-77870e64dc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 2.7402 - accuracy: 0.6303\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49907, saving model to Model.hdf5\n",
            "95/95 [==============================] - 186s 1s/step - loss: 2.7402 - accuracy: 0.6303 - val_loss: 0.7218 - val_accuracy: 0.4991\n",
            "Epoch 2/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.8067\n",
            "Epoch 2: val_accuracy improved from 0.49907 to 0.51258, saving model to Model.hdf5\n",
            "95/95 [==============================] - 127s 1s/step - loss: 0.5725 - accuracy: 0.8067 - val_loss: 1.3847 - val_accuracy: 0.5126\n",
            "Epoch 3/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8475\n",
            "Epoch 3: val_accuracy improved from 0.51258 to 0.59553, saving model to Model.hdf5\n",
            "95/95 [==============================] - 137s 1s/step - loss: 0.3534 - accuracy: 0.8475 - val_loss: 1.0919 - val_accuracy: 0.5955\n",
            "Epoch 4/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.8580\n",
            "Epoch 4: val_accuracy did not improve from 0.59553\n",
            "95/95 [==============================] - 57s 600ms/step - loss: 0.3474 - accuracy: 0.8580 - val_loss: 1.5154 - val_accuracy: 0.5555\n",
            "Epoch 5/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.8534\n",
            "Epoch 5: val_accuracy improved from 0.59553 to 0.82432, saving model to Model.hdf5\n",
            "95/95 [==============================] - 142s 2s/step - loss: 0.5001 - accuracy: 0.8534 - val_loss: 0.4090 - val_accuracy: 0.8243\n",
            "Epoch 6/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8524\n",
            "Epoch 6: val_accuracy improved from 0.82432 to 0.83178, saving model to Model.hdf5\n",
            "95/95 [==============================] - 162s 2s/step - loss: 0.3458 - accuracy: 0.8524 - val_loss: 0.3635 - val_accuracy: 0.8318\n",
            "Epoch 7/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.8715\n",
            "Epoch 7: val_accuracy improved from 0.83178 to 0.85322, saving model to Model.hdf5\n",
            "95/95 [==============================] - 162s 2s/step - loss: 0.3024 - accuracy: 0.8715 - val_loss: 0.3227 - val_accuracy: 0.8532\n",
            "Epoch 8/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.8821\n",
            "Epoch 8: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.2798 - accuracy: 0.8821 - val_loss: 0.4389 - val_accuracy: 0.8187\n",
            "Epoch 9/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.8860\n",
            "Epoch 9: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.2658 - accuracy: 0.8860 - val_loss: 0.3421 - val_accuracy: 0.8486\n",
            "Epoch 10/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.8925\n",
            "Epoch 10: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 590ms/step - loss: 0.2568 - accuracy: 0.8925 - val_loss: 0.5540 - val_accuracy: 0.8020\n",
            "Epoch 11/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9011\n",
            "Epoch 11: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.2355 - accuracy: 0.9011 - val_loss: 0.4049 - val_accuracy: 0.8425\n",
            "Epoch 12/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9082\n",
            "Epoch 12: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.2194 - accuracy: 0.9082 - val_loss: 0.3622 - val_accuracy: 0.8476\n",
            "Epoch 13/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9135\n",
            "Epoch 13: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.2114 - accuracy: 0.9135 - val_loss: 0.3571 - val_accuracy: 0.8490\n",
            "Epoch 14/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9188\n",
            "Epoch 14: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.1948 - accuracy: 0.9188 - val_loss: 0.4003 - val_accuracy: 0.8285\n",
            "Epoch 15/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9237\n",
            "Epoch 15: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.1861 - accuracy: 0.9237 - val_loss: 0.3822 - val_accuracy: 0.8495\n",
            "Epoch 16/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9274\n",
            "Epoch 16: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 598ms/step - loss: 0.1789 - accuracy: 0.9274 - val_loss: 0.4327 - val_accuracy: 0.8192\n",
            "Epoch 17/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9290\n",
            "Epoch 17: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 86s 601ms/step - loss: 0.1755 - accuracy: 0.9290 - val_loss: 0.4198 - val_accuracy: 0.8523\n",
            "Epoch 18/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.9041\n",
            "Epoch 18: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 595ms/step - loss: 0.3507 - accuracy: 0.9041 - val_loss: 502169.8750 - val_accuracy: 0.5550\n",
            "Epoch 19/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.9144 - accuracy: 0.6412\n",
            "Epoch 19: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 590ms/step - loss: 0.9144 - accuracy: 0.6412 - val_loss: 89957.3672 - val_accuracy: 0.5550\n",
            "Epoch 20/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8207\n",
            "Epoch 20: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 83s 878ms/step - loss: 0.3998 - accuracy: 0.8207 - val_loss: 7.6985 - val_accuracy: 0.5550\n",
            "Epoch 21/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 1.4230 - accuracy: 0.6649\n",
            "Epoch 21: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 601ms/step - loss: 1.4230 - accuracy: 0.6649 - val_loss: 5559.1089 - val_accuracy: 0.5550\n",
            "Epoch 22/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8168\n",
            "Epoch 22: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.4208 - accuracy: 0.8168 - val_loss: 0.8722 - val_accuracy: 0.5541\n",
            "Epoch 23/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8401\n",
            "Epoch 23: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 590ms/step - loss: 0.3648 - accuracy: 0.8401 - val_loss: 0.4176 - val_accuracy: 0.8187\n",
            "Epoch 24/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.8500\n",
            "Epoch 24: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.3562 - accuracy: 0.8500 - val_loss: 0.3801 - val_accuracy: 0.8225\n",
            "Epoch 25/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8594\n",
            "Epoch 25: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 595ms/step - loss: 0.3302 - accuracy: 0.8594 - val_loss: 0.3665 - val_accuracy: 0.8392\n",
            "Epoch 26/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.8585\n",
            "Epoch 26: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.3423 - accuracy: 0.8585 - val_loss: 0.3680 - val_accuracy: 0.8374\n",
            "Epoch 27/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8670\n",
            "Epoch 27: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.3109 - accuracy: 0.8670 - val_loss: 0.3545 - val_accuracy: 0.8406\n",
            "Epoch 28/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8716\n",
            "Epoch 28: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.3027 - accuracy: 0.8716 - val_loss: 0.3634 - val_accuracy: 0.8490\n",
            "Epoch 29/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8734\n",
            "Epoch 29: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.2983 - accuracy: 0.8734 - val_loss: 0.7467 - val_accuracy: 0.7018\n",
            "Epoch 30/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.8813\n",
            "Epoch 30: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.2825 - accuracy: 0.8813 - val_loss: 0.3608 - val_accuracy: 0.8322\n",
            "Epoch 31/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.8836\n",
            "Epoch 31: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.2796 - accuracy: 0.8836 - val_loss: 0.3527 - val_accuracy: 0.8364\n",
            "Epoch 32/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.8828\n",
            "Epoch 32: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.2773 - accuracy: 0.8828 - val_loss: 0.5268 - val_accuracy: 0.7717\n",
            "Epoch 33/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.8893\n",
            "Epoch 33: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.2686 - accuracy: 0.8893 - val_loss: 0.5276 - val_accuracy: 0.8071\n",
            "Epoch 34/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2678 - accuracy: 0.8888\n",
            "Epoch 34: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.2678 - accuracy: 0.8888 - val_loss: 0.3430 - val_accuracy: 0.8458\n",
            "Epoch 35/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.8934\n",
            "Epoch 35: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.2562 - accuracy: 0.8934 - val_loss: 0.3413 - val_accuracy: 0.8481\n",
            "Epoch 36/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.8963\n",
            "Epoch 36: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.2476 - accuracy: 0.8963 - val_loss: 0.4818 - val_accuracy: 0.8173\n",
            "Epoch 37/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.8990\n",
            "Epoch 37: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.2442 - accuracy: 0.8990 - val_loss: 0.6258 - val_accuracy: 0.8122\n",
            "Epoch 38/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9038\n",
            "Epoch 38: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.2339 - accuracy: 0.9038 - val_loss: 0.4811 - val_accuracy: 0.7889\n",
            "Epoch 39/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9066\n",
            "Epoch 39: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.2310 - accuracy: 0.9066 - val_loss: 0.3396 - val_accuracy: 0.8476\n",
            "Epoch 40/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9062\n",
            "Epoch 40: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.2233 - accuracy: 0.9062 - val_loss: 0.6738 - val_accuracy: 0.8001\n",
            "Epoch 41/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9098\n",
            "Epoch 41: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.2194 - accuracy: 0.9098 - val_loss: 0.4112 - val_accuracy: 0.8243\n",
            "Epoch 42/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9080\n",
            "Epoch 42: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.2149 - accuracy: 0.9080 - val_loss: 0.3778 - val_accuracy: 0.8411\n",
            "Epoch 43/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9144\n",
            "Epoch 43: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.2090 - accuracy: 0.9144 - val_loss: 0.7543 - val_accuracy: 0.7847\n",
            "Epoch 44/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2033 - accuracy: 0.9158\n",
            "Epoch 44: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.2033 - accuracy: 0.9158 - val_loss: 0.4080 - val_accuracy: 0.8453\n",
            "Epoch 45/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9181\n",
            "Epoch 45: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.1959 - accuracy: 0.9181 - val_loss: 0.3520 - val_accuracy: 0.8467\n",
            "Epoch 46/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9226\n",
            "Epoch 46: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.1917 - accuracy: 0.9226 - val_loss: 0.5706 - val_accuracy: 0.8192\n",
            "Epoch 47/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9233\n",
            "Epoch 47: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 590ms/step - loss: 0.1885 - accuracy: 0.9233 - val_loss: 0.3855 - val_accuracy: 0.8476\n",
            "Epoch 48/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9266\n",
            "Epoch 48: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.1793 - accuracy: 0.9266 - val_loss: 0.4061 - val_accuracy: 0.8453\n",
            "Epoch 49/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9291\n",
            "Epoch 49: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.1703 - accuracy: 0.9291 - val_loss: 0.5754 - val_accuracy: 0.8234\n",
            "Epoch 50/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9339\n",
            "Epoch 50: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.1668 - accuracy: 0.9339 - val_loss: 0.5983 - val_accuracy: 0.8262\n",
            "Epoch 51/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9384\n",
            "Epoch 51: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.1537 - accuracy: 0.9384 - val_loss: 0.5006 - val_accuracy: 0.8350\n",
            "Epoch 52/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9371\n",
            "Epoch 52: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 595ms/step - loss: 0.1584 - accuracy: 0.9371 - val_loss: 0.5032 - val_accuracy: 0.8313\n",
            "Epoch 53/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9434\n",
            "Epoch 53: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.1449 - accuracy: 0.9434 - val_loss: 0.5816 - val_accuracy: 0.8360\n",
            "Epoch 54/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9429\n",
            "Epoch 54: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.1422 - accuracy: 0.9429 - val_loss: 0.5663 - val_accuracy: 0.8397\n",
            "Epoch 55/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.9424\n",
            "Epoch 55: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.1468 - accuracy: 0.9424 - val_loss: 0.7481 - val_accuracy: 0.8034\n",
            "Epoch 56/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9446\n",
            "Epoch 56: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 595ms/step - loss: 0.1410 - accuracy: 0.9446 - val_loss: 0.4757 - val_accuracy: 0.8336\n",
            "Epoch 57/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9498\n",
            "Epoch 57: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 596ms/step - loss: 0.1263 - accuracy: 0.9498 - val_loss: 0.5587 - val_accuracy: 0.8364\n",
            "Epoch 58/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9507\n",
            "Epoch 58: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.1238 - accuracy: 0.9507 - val_loss: 0.9742 - val_accuracy: 0.6985\n",
            "Epoch 59/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9547\n",
            "Epoch 59: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 588ms/step - loss: 0.1170 - accuracy: 0.9547 - val_loss: 0.9956 - val_accuracy: 0.8048\n",
            "Epoch 60/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9574\n",
            "Epoch 60: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 591ms/step - loss: 0.1083 - accuracy: 0.9574 - val_loss: 0.5150 - val_accuracy: 0.8402\n",
            "Epoch 61/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9575\n",
            "Epoch 61: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 591ms/step - loss: 0.1102 - accuracy: 0.9575 - val_loss: 0.4804 - val_accuracy: 0.8318\n",
            "Epoch 62/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9577\n",
            "Epoch 62: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.1092 - accuracy: 0.9577 - val_loss: 0.5323 - val_accuracy: 0.8378\n",
            "Epoch 63/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9607\n",
            "Epoch 63: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.1023 - accuracy: 0.9607 - val_loss: 0.5591 - val_accuracy: 0.8388\n",
            "Epoch 64/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9611\n",
            "Epoch 64: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.0988 - accuracy: 0.9611 - val_loss: 1.0227 - val_accuracy: 0.8173\n",
            "Epoch 65/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9635\n",
            "Epoch 65: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 590ms/step - loss: 0.0934 - accuracy: 0.9635 - val_loss: 0.6016 - val_accuracy: 0.8453\n",
            "Epoch 66/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9642\n",
            "Epoch 66: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 598ms/step - loss: 0.0922 - accuracy: 0.9642 - val_loss: 0.5343 - val_accuracy: 0.8313\n",
            "Epoch 67/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9704\n",
            "Epoch 67: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.0775 - accuracy: 0.9704 - val_loss: 1.0186 - val_accuracy: 0.8374\n",
            "Epoch 68/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9676\n",
            "Epoch 68: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 598ms/step - loss: 0.0858 - accuracy: 0.9676 - val_loss: 0.5941 - val_accuracy: 0.8397\n",
            "Epoch 69/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9714\n",
            "Epoch 69: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 57s 597ms/step - loss: 0.0775 - accuracy: 0.9714 - val_loss: 1.1728 - val_accuracy: 0.8169\n",
            "Epoch 70/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9682\n",
            "Epoch 70: val_accuracy did not improve from 0.85322\n",
            "95/95 [==============================] - 56s 589ms/step - loss: 0.0812 - accuracy: 0.9682 - val_loss: 0.7878 - val_accuracy: 0.8327\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compilation du modele en definissant la fonction de perte, l'optimisateur et la valeur afficher durant l'entrainement\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Sauvegarde du modèle ayant le meilleur val_accuracy pendant l'entraînement dans Model.hdf5. \n",
        "modelsPath = \"Model.hdf5\"\n",
        "modelcheckpoint = ModelCheckpoint(filepath=modelsPath,\n",
        "                                  monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "# entrainement du modele\n",
        "classifier = model.fit(X_train, y_train,\n",
        "                       epochs=70, # nombre d' poques\n",
        "                       batch_size=180, # nombre d'images entrain es ensemble\n",
        "                       validation_data=(X_val, y_val), # donn es de validation\n",
        "                       verbose=1, # mets cette valeur   0, si vous voulez ne pas afficher les d tails d'entrainement\n",
        "                       callbacks=[modelcheckpoint], # les fonctions   appeler   la fin de chaque  poque (dans ce cas modelcheckpoint: qui sauvegarde le mod le)\n",
        "                       shuffle=True)# shuffle les images\n",
        "\n",
        "# ==========================================\n",
        "# ========AFFICHAGE DES RESULTATS===========\n",
        "# ==========================================\n",
        "\n",
        "# Plot accuracy over epochs (precision par  poque)\n",
        "print(classifier.history.keys())\n",
        "plt.plot(classifier.history['accuracy'])\n",
        "plt.plot(classifier.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "fig = plt.gcf()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teiHOLbPrf2B",
        "outputId": "8d73d98b-0437-4edd-decc-8b42c963784c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68/68 [==============================] - 5s 37ms/step\n",
            "Acc= 0.8447636700648748\n",
            "precision= 0.8447636700648748\n",
            "recall= 0.8447636700648748\n",
            "f1= 0.8447636700648748\n",
            "************************\n",
            "84.47636700648748\n",
            "**********\n",
            "15.523632993512512\n"
          ]
        }
      ],
      "source": [
        "# Chargement du modèle à partir du fichier spécifié.\n",
        "model_path = \"Model.hdf5\"\n",
        "Classifier : Model = load_model(model_path)\n",
        "\n",
        "\n",
        "#Utilisation du modèle pour effectuer des prédictions sur l'ensemble de test \n",
        "# et Arrondissement des prédictions à la classe la plus probable (0 ou 1 dans le cas d'une classification binaire).\n",
        "predicted_classes = Classifier.predict(X_test)\n",
        "predicted_classes = np.round(predicted_classes)\n",
        "\n",
        "#Calcul et affichage des métriques de performance \n",
        "acc=accuracy_score(y_test, predicted_classes)\n",
        "precision=precision_score(y_test, predicted_classes, average='micro')\n",
        "recall=recall_score(y_test, predicted_classes, average='micro')\n",
        "f1=f1_score(y_test, predicted_classes, average='micro')\n",
        "t=0\n",
        "f=0\n",
        "for i in range(len(predicted_classes)):\n",
        "\n",
        "    if  False in (y_test[i]==predicted_classes[i]):\n",
        "        f=f+1\n",
        "    else:\n",
        "        t=t+1\n",
        "\n",
        "print(\"Acc=\",acc)\n",
        "print(\"precision=\",precision)\n",
        "print(\"recall=\",recall)\n",
        "print(\"f1=\",f1)\n",
        "print(\"************************\")\n",
        "print ((t/len(y_test))*100)\n",
        "print(\"**********\")\n",
        "print ((f/len(y_test))*100)\n",
        "\n",
        "\n",
        "# Cette fonction renvoie les indices des échantillons bien classés pour chaque classe.\n",
        "# Elle prend en parametre x la liste des classes des donnees de test\n",
        "# Elle retourne les listes des indices de chaque classe.\n",
        "def nbMalVal(x):\n",
        "    Norm=[]\n",
        "    Mi=[]\n",
        "    Sttc=[]\n",
        "    Cd=[]\n",
        "    Hyp=[]\n",
        "    for i in range(len(x)):\n",
        "        if x[i][0]==1:\n",
        "            Norm.append(i)\n",
        "        elif x[i][1]==1:\n",
        "            Mi.append(i)\n",
        "        elif x[i][2]==1:\n",
        "            Sttc.append(i)\n",
        "        elif x[i][3]==1:\n",
        "            Cd.append(i)\n",
        "        elif x[i][4]==1:\n",
        "            Hyp.append(i)\n",
        "\n",
        "    return Norm, Mi, Sttc, Cd, Hyp\n",
        "\n",
        "\n",
        "# Cette fonction calcule le pourcentage de prédictions correctes et incorrectes pour une classe donnée.\n",
        "# Elle prend en parametre Norm la liste d'indice d'une classes .\n",
        "# Elle retourne le pourcentages de prédictions correctes et incorrectes.\n",
        "def resultPrct(Norm):\n",
        "  t=0\n",
        "  f=0\n",
        "  for i in range(len(Norm)):\n",
        "    if  False in (y_test[Norm[i]]==predicted_classes[Norm[i]]):\n",
        "        f=f+1\n",
        "    else:\n",
        "        t=t+1\n",
        "  true = ((t/len(Norm))*100)\n",
        "  false= ((f/len(Norm))*100)\n",
        "  return true, false\n",
        "\n",
        "\n",
        "# Affichage du pourcentage de prédictions correctes (true) et incorrectes (false) pour chaque classe.\n",
        "Norm, Mi, Sttc, Cd, Hyp=nbMalVal(y_test)\n",
        "Nt, Nf = resultPrct(Norm)\n",
        "Mt, Mf = resultPrct(Mi)\n",
        "St, Sf = resultPrct(Sttc)\n",
        "Ct, Cf = resultPrct(Cd)\n",
        "Ht, Hf = resultPrct(Hyp)\n",
        "print(Nt, Nf, Mt, Mf, St, Sf, Ct, Cf, Ht,Hf)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
