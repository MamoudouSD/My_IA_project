{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================================================\n",
        "# DIANI Mamoudou Sékou\n",
        "#\n",
        "# Aout 2023\n",
        "#==========================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import ast\n",
        "from scipy import stats\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Conv2D, MaxPooling2D, Add, MaxPooling1D, Input, BatchNormalization, UpSampling2D, Activation, Dropout, Flatten, Dense, Lambda, Concatenate, GlobalAveragePooling1D\n",
        "from keras import backend\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "from keras.models import load_model\n",
        "from keras import Model\n",
        "\n",
        "# Importation des bibliothèques nécessaires pour le traitement d'images avec TensorFlow et Keras\n",
        "import tensorflow as tf\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Utilisation du module XLA pour accelerer les calculs\n",
        "from tensorflow._api.v2.compat.v1 import xl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyZEBNA5OZFO"
      },
      "outputs": [],
      "source": [
        "# Cette fonction charge les données brutes à partir des fichiers ECG en utilisant la bibliothèque wfdb.\n",
        "# Elle prend en parametre le dataFrame contenant les informations sur les fichiers, le taux d'échantillonnage des signaux\n",
        "# Le chemin vers le répertoire contenant les fichiers et renvoie un tableau contenant les signaux bruts.\n",
        "def load_raw_data(df, sampling_rate, path):\n",
        "    if sampling_rate == 100:\n",
        "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
        "    else:\n",
        "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
        "    data = np.array([signal for signal, meta in data])\n",
        "    return data\n",
        "\n",
        "# Chemin vers le répertoire contenant les fichiers\n",
        "path = '/Users/mamoudousdiani/Documents/UQAM/projet_master/Base_de_donnee/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3/'\n",
        "\n",
        "# Taux d'échantillonnage\n",
        "sampling_rate=100\n",
        "\n",
        "# Chargement et convertion des données d'annotation\n",
        "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
        "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "# # Chargement des données brutes des signaux\n",
        "X = load_raw_data(Y, sampling_rate, path)\n",
        "\n",
        "# Chargement de scp_statements.csv pour l'agrégation diagnostique\n",
        "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
        "agg_df = agg_df[agg_df.diagnostic == 1]\n",
        "\n",
        "\n",
        "# Cette fonction agrège les diagnostics en utilisant le fichier scp_statements.csv\n",
        "# Elle prend comme parametre un dictionnaire contenant les codes de diagnostic\n",
        "# Et renvoie la liste des classes diagnostiques agrégées\n",
        "# La fonction parcourt les clés du dictionnaire (y_dic) et vérifie si chaque \n",
        "# clé existe dans le fichier scp_statements.csv (représenté par le DataFrame agg_df).\n",
        "# Si la clé existe, la fonction ajoute la classe diagnostique correspondante à la liste temporaire.\n",
        "# Enfin, la fonction utilise un ensemble (set) pour éliminer les doublons, puis convertit cet ensemble en liste et la renvoie.\n",
        "def aggregate_diagnostic(y_dic):\n",
        "    tmp = []\n",
        "    for key in y_dic.keys():\n",
        "        if key in agg_df.index:\n",
        "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
        "    return list(set(tmp))\n",
        "\n",
        "# Appliquation de la superclasse diagnostique\n",
        "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
        "\n",
        "# Séparation des données en ensembles d'entraînement, de validation et de test\n",
        "test_fold = 9\n",
        "# Train\n",
        "X_train1 = X[np.where(Y.strat_fold < test_fold)]\n",
        "y_train1 = Y[(Y.strat_fold < test_fold)].diagnostic_superclass\n",
        "# validation\n",
        "X_val1 = X[np.where(Y.strat_fold == test_fold)]\n",
        "y_val1 = Y[Y.strat_fold == test_fold].diagnostic_superclass\n",
        "# Test\n",
        "X_test1 = X[np.where(Y.strat_fold > test_fold)]\n",
        "y_test1 = Y[Y.strat_fold > test_fold].diagnostic_superclass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH7kbK7IOcky"
      },
      "outputs": [],
      "source": [
        "# Cette fonction convertit les codes de diagnostic en un tableau de classe diagnostique.\n",
        "# Elle prend en paramètre X un dictionnaire contenant les codes de diagnostic pour un enregistrement ECG\n",
        "# et renvoie un Tableau de classe diagnostique encodé, la liste des indices des diagnostics valides.\n",
        "# et la liste des indices des diagnostics non valides\n",
        "def convY(x):\n",
        "    a=x.keys()\n",
        "    d=[]\n",
        "    listeV=[]\n",
        "    listeNV=[]\n",
        "    lv=0\n",
        "    N=0\n",
        "    M=0\n",
        "    S=0\n",
        "    C=0\n",
        "    H=0\n",
        "    bof=0\n",
        "    for i in range(len(a)):\n",
        "        if 'NORM' in x[a[i]]:\n",
        "            d.append([1, 0, 0, 0, 0])\n",
        "            #listeV.append(i)\n",
        "            N=N+1\n",
        "        elif 'MI' in x[a[i]]:\n",
        "            d.append([0, 1, 0, 0, 0])\n",
        "            listeV.append(i)\n",
        "            M=M+1\n",
        "        elif 'STTC' in x[a[i]]:\n",
        "            d.append([0, 0, 1, 0, 0])\n",
        "            listeV.append(i)\n",
        "            S=S+1\n",
        "        elif 'CD' in x[a[i]]:\n",
        "            d.append([0, 0, 0, 1, 0])\n",
        "            listeV.append(i)\n",
        "            C=C+1\n",
        "        elif 'HYP' in x[a[i]]:\n",
        "            d.append([0, 0, 0, 0, 1])\n",
        "            listeV.append(i)\n",
        "            H=H+1\n",
        "        else:\n",
        "            d.append([0, 0, 0, 0, 0])\n",
        "            listeNV.append(i)\n",
        "            bof=bof+1\n",
        "        lv=lv+1\n",
        "\n",
        "    d= np.array(d)\n",
        "    print(N,M,S,C,H,bof)\n",
        "    return d, listeV, listeNV\n",
        "\n",
        "\n",
        "# Cette fonction calcule la moyenne et l'écart type des valeurs dans une liste tridimensionnelle\n",
        "# Elle prend en paramètre une liste tridimensionnelle contenant les valeurs\n",
        "# Elle retourne la moyenne et l'ecart type des valeurs\n",
        "def calcul(X_train):\n",
        "    a=0\n",
        "    nb=0\n",
        "    for i in range(len(X_train)):\n",
        "        for j in range(len(X_train[i])):\n",
        "            for k in range(len(X_train[i][j])):\n",
        "                a=a+X_train[i][j][k]\n",
        "                nb=nb+1\n",
        "    moy=a/nb\n",
        "    b=0\n",
        "    for i in range(len(X_train)):\n",
        "        for j in range(len(X_train[i])):\n",
        "            for k in range(len(X_train[i][j])):\n",
        "                b=b+((X_train[i][j][k]-moy)**2)\n",
        "    ecT=sqrt(b/nb)\n",
        "    return moy, ecT\n",
        "\n",
        "\n",
        "# Cette fonction normalise une liste tridimensionnelle en utilisant la moyenne et l'écart type.\n",
        "# Elle prend en paramètre une liste tridimensionnelle à normaliser, la moyenne des valeurs utilisée pour la normalisation\n",
        "# l'ecart type des valeurs utilisé pour la normalisation.\n",
        "# Elle retourne une liste tridimensionnelle normalisée.\n",
        "def normalisation(l,moy, ecT):\n",
        "    for i in range(len(l)):\n",
        "        for j in range(len(l[i])):\n",
        "            for k in range(len(l[i][j])):\n",
        "                l[i][j][k] = (l[i][j][k]-moy)/(ecT)\n",
        "    return l\n",
        "\n",
        "\n",
        "# Cette fonction supprime les éléments non valides (pas de classe) d'une liste \n",
        "# en utilisant la liste des indices des diagnostics non valides.\n",
        "# Elle prend en paramètre X_train et y_train les listes de signaux et de leures classes \n",
        "# lnv la liste contenant les indices des éléments non valides\n",
        "# Elle retourne les liste contenant les éléments valides correspondant aux indices fournis\n",
        "def dataConcr(X_train, y_train, lnv):\n",
        "    dataX=[]\n",
        "    dataY=[]\n",
        "    for i in range(len (X_train)):\n",
        "        if i not in lnv:\n",
        "            dataX.append(X_train[i])\n",
        "            dataY.append(y_train[i])\n",
        "\n",
        "    return (stats.zscore(np.array(dataX)), np.array(dataY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWupMyw7FW3O"
      },
      "outputs": [],
      "source": [
        "# Convertir les labels de la classe en vecteurs binaires\n",
        "y_train, lv_train, lnv_train = convY(y_train1)\n",
        "y_val, lv_val, lnv_val=convY(y_val1)\n",
        "y_test, lv_test, lnv_test=convY(y_test1)\n",
        "\n",
        "# Traitement des données d'entraînement\n",
        "X_train, y_train=dataConcr(X_train1, y_train, lnv_train)\n",
        "X_val, y_val=dataConcr(X_val1, y_val, lnv_val)\n",
        "X_test, y_test=dataConcr(X_test1, y_test, lnv_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GECb4xl7y8u9"
      },
      "outputs": [],
      "source": [
        "# Calculer la forme des données d'entrée\n",
        "dataShape = (len(X_train[0]), len(X_train[0][0]))\n",
        "# Créer un objet d'entrée pour le modèle avec la forme calculée\n",
        "img_input = Input(shape=dataShape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95E7d3Fsy8rs",
        "outputId": "03360c7d-03cc-4a2b-9213-6f097ccf1248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1000, 12)]        0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1000, 64)          2368      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1000, 64)          0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 1000, 64)          12352     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1000, 64)          0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 1000, 64)         256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 500, 64)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 500, 128)          24704     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 500, 128)          0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 500, 128)          49280     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 500, 128)          0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 500, 128)         512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 250, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 250, 256)          98560     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 250, 256)          0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 250, 256)          196864    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 250, 256)          0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 250, 256)          196864    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 250, 256)          0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 250, 256)         1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 125, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 125, 512)          393728    \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 125, 512)          0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 125, 512)          786944    \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 125, 512)          0         \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 125, 512)          786944    \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 125, 512)          0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 125, 512)         2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 62, 512)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 62, 512)           786944    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 62, 512)           0         \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 62, 512)           786944    \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 62, 512)           0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 62, 512)           786944    \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 62, 512)           0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 62, 512)          2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 31, 512)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 15872)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              65015808  \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 20485     \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,732,933\n",
            "Trainable params: 86,729,989\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Création d'une architecture basée sur VGG16\n",
        "# pour l'extraction des caractéristiques à partir de séquences temporelles 1D.\n",
        "def feature_extraction(input):\n",
        "    x = Conv1D(64, 3, padding= \"same\")(input)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(64, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv1D(128, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(128, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv1D(256, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(256, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(256, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv1D(512, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(512, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(512, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv1D(512, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(512, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(512, 3, padding= \"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    encoded = MaxPooling1D(pool_size=2)(x)# L'ensemble des features/caract ristiques extraits\n",
        "    return encoded\n",
        "\n",
        "# Partie completement connectee (Fully Connected Layer) pour la classification multiclasse.\n",
        "def fully_connected(encoded):\n",
        "    x = Flatten()(encoded)\n",
        "    x = Dense(4096)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Dense(4096)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dense(5)(x)\n",
        "    sortie = Activation('sigmoid')(x)\n",
        "    return sortie\n",
        "\n",
        "# Declaration du modele:\n",
        "model = Model(img_input, fully_connected(feature_extraction(img_input)))\n",
        "\n",
        "# Affichage des parametres du modele\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hfmBg2Aty8pA",
        "outputId": "cfd356e3-b260-4f55-f4b1-561b1535c56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.6023\n",
            "Epoch 1: val_accuracy improved from -inf to 0.33691, saving model to Model.hdf5\n",
            "95/95 [==============================] - 138s 1s/step - loss: 0.7291 - accuracy: 0.6023 - val_loss: 0.4780 - val_accuracy: 0.3369\n",
            "Epoch 2/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.7235\n",
            "Epoch 2: val_accuracy improved from 0.33691 to 0.51118, saving model to Model.hdf5\n",
            "95/95 [==============================] - 143s 2s/step - loss: 0.2630 - accuracy: 0.7235 - val_loss: 0.4906 - val_accuracy: 0.5112\n",
            "Epoch 3/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.7588\n",
            "Epoch 3: val_accuracy improved from 0.51118 to 0.55871, saving model to Model.hdf5\n",
            "95/95 [==============================] - 143s 2s/step - loss: 0.2326 - accuracy: 0.7588 - val_loss: 0.4376 - val_accuracy: 0.5587\n",
            "Epoch 4/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.7811\n",
            "Epoch 4: val_accuracy improved from 0.55871 to 0.69571, saving model to Model.hdf5\n",
            "95/95 [==============================] - 149s 2s/step - loss: 0.2109 - accuracy: 0.7811 - val_loss: 0.2797 - val_accuracy: 0.6957\n",
            "Epoch 5/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.7930\n",
            "Epoch 5: val_accuracy did not improve from 0.69571\n",
            "95/95 [==============================] - 28s 289ms/step - loss: 0.1987 - accuracy: 0.7930 - val_loss: 0.3871 - val_accuracy: 0.6710\n",
            "Epoch 6/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.8032\n",
            "Epoch 6: val_accuracy improved from 0.69571 to 0.71202, saving model to Model.hdf5\n",
            "95/95 [==============================] - 169s 2s/step - loss: 0.1875 - accuracy: 0.8032 - val_loss: 0.3228 - val_accuracy: 0.7120\n",
            "Epoch 7/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.8168\n",
            "Epoch 7: val_accuracy improved from 0.71202 to 0.73672, saving model to Model.hdf5\n",
            "95/95 [==============================] - 174s 2s/step - loss: 0.1765 - accuracy: 0.8168 - val_loss: 0.2805 - val_accuracy: 0.7367\n",
            "Epoch 8/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.8341\n",
            "Epoch 8: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 292ms/step - loss: 0.1619 - accuracy: 0.8341 - val_loss: 0.2944 - val_accuracy: 0.7069\n",
            "Epoch 9/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.8445\n",
            "Epoch 9: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 294ms/step - loss: 0.1531 - accuracy: 0.8445 - val_loss: 0.3237 - val_accuracy: 0.7111\n",
            "Epoch 10/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.8582\n",
            "Epoch 10: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 288ms/step - loss: 0.1402 - accuracy: 0.8582 - val_loss: 0.3203 - val_accuracy: 0.6692\n",
            "Epoch 11/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.8736\n",
            "Epoch 11: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 285ms/step - loss: 0.1265 - accuracy: 0.8736 - val_loss: 0.4072 - val_accuracy: 0.6705\n",
            "Epoch 12/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.8894\n",
            "Epoch 12: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 290ms/step - loss: 0.1158 - accuracy: 0.8894 - val_loss: 0.3435 - val_accuracy: 0.6952\n",
            "Epoch 13/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9036\n",
            "Epoch 13: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 290ms/step - loss: 0.0965 - accuracy: 0.9036 - val_loss: 0.4714 - val_accuracy: 0.6221\n",
            "Epoch 14/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9219\n",
            "Epoch 14: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0818 - accuracy: 0.9219 - val_loss: 0.4391 - val_accuracy: 0.6640\n",
            "Epoch 15/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9319\n",
            "Epoch 15: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0715 - accuracy: 0.9319 - val_loss: 0.4243 - val_accuracy: 0.6417\n",
            "Epoch 16/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9381\n",
            "Epoch 16: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 287ms/step - loss: 0.0670 - accuracy: 0.9381 - val_loss: 0.4800 - val_accuracy: 0.6626\n",
            "Epoch 17/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9505\n",
            "Epoch 17: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 290ms/step - loss: 0.0552 - accuracy: 0.9505 - val_loss: 0.5132 - val_accuracy: 0.6999\n",
            "Epoch 18/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9599\n",
            "Epoch 18: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 290ms/step - loss: 0.0475 - accuracy: 0.9599 - val_loss: 0.4579 - val_accuracy: 0.7064\n",
            "Epoch 19/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9663\n",
            "Epoch 19: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 290ms/step - loss: 0.0386 - accuracy: 0.9663 - val_loss: 0.5306 - val_accuracy: 0.7060\n",
            "Epoch 20/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9692\n",
            "Epoch 20: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 290ms/step - loss: 0.0359 - accuracy: 0.9692 - val_loss: 0.5372 - val_accuracy: 0.6938\n",
            "Epoch 21/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9680\n",
            "Epoch 21: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0370 - accuracy: 0.9680 - val_loss: 0.5368 - val_accuracy: 0.7307\n",
            "Epoch 22/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9719\n",
            "Epoch 22: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 287ms/step - loss: 0.0336 - accuracy: 0.9719 - val_loss: 0.6206 - val_accuracy: 0.7125\n",
            "Epoch 23/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9809\n",
            "Epoch 23: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0226 - accuracy: 0.9809 - val_loss: 0.6582 - val_accuracy: 0.7223\n",
            "Epoch 24/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9776\n",
            "Epoch 24: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0281 - accuracy: 0.9776 - val_loss: 0.5936 - val_accuracy: 0.6337\n",
            "Epoch 25/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9830\n",
            "Epoch 25: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 287ms/step - loss: 0.0223 - accuracy: 0.9830 - val_loss: 0.6061 - val_accuracy: 0.7022\n",
            "Epoch 26/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9778\n",
            "Epoch 26: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0275 - accuracy: 0.9778 - val_loss: 0.6136 - val_accuracy: 0.6831\n",
            "Epoch 27/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9830\n",
            "Epoch 27: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0216 - accuracy: 0.9830 - val_loss: 0.6531 - val_accuracy: 0.7055\n",
            "Epoch 28/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9845\n",
            "Epoch 28: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0180 - accuracy: 0.9845 - val_loss: 0.6216 - val_accuracy: 0.7120\n",
            "Epoch 29/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9887\n",
            "Epoch 29: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0146 - accuracy: 0.9887 - val_loss: 0.6246 - val_accuracy: 0.7088\n",
            "Epoch 30/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9889\n",
            "Epoch 30: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0141 - accuracy: 0.9889 - val_loss: 0.6693 - val_accuracy: 0.6715\n",
            "Epoch 31/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9816\n",
            "Epoch 31: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0221 - accuracy: 0.9816 - val_loss: 0.6431 - val_accuracy: 0.7171\n",
            "Epoch 32/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9884\n",
            "Epoch 32: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0150 - accuracy: 0.9884 - val_loss: 0.5929 - val_accuracy: 0.6692\n",
            "Epoch 33/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9903\n",
            "Epoch 33: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 290ms/step - loss: 0.0132 - accuracy: 0.9903 - val_loss: 0.7058 - val_accuracy: 0.7097\n",
            "Epoch 34/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9906\n",
            "Epoch 34: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 290ms/step - loss: 0.0117 - accuracy: 0.9906 - val_loss: 0.6513 - val_accuracy: 0.6831\n",
            "Epoch 35/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9878\n",
            "Epoch 35: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0169 - accuracy: 0.9878 - val_loss: 0.6054 - val_accuracy: 0.6701\n",
            "Epoch 36/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9886\n",
            "Epoch 36: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0132 - accuracy: 0.9886 - val_loss: 0.8163 - val_accuracy: 0.6920\n",
            "Epoch 37/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9891\n",
            "Epoch 37: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0131 - accuracy: 0.9891 - val_loss: 0.5852 - val_accuracy: 0.6873\n",
            "Epoch 38/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9838\n",
            "Epoch 38: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0211 - accuracy: 0.9838 - val_loss: 0.5725 - val_accuracy: 0.6831\n",
            "Epoch 39/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9899\n",
            "Epoch 39: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0123 - accuracy: 0.9899 - val_loss: 0.8130 - val_accuracy: 0.6901\n",
            "Epoch 40/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9904\n",
            "Epoch 40: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0127 - accuracy: 0.9904 - val_loss: 0.6455 - val_accuracy: 0.6841\n",
            "Epoch 41/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9869\n",
            "Epoch 41: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0174 - accuracy: 0.9869 - val_loss: 0.7212 - val_accuracy: 0.6831\n",
            "Epoch 42/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9866\n",
            "Epoch 42: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0200 - accuracy: 0.9866 - val_loss: 0.6362 - val_accuracy: 0.6496\n",
            "Epoch 43/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9690\n",
            "Epoch 43: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0438 - accuracy: 0.9690 - val_loss: 0.7075 - val_accuracy: 0.6333\n",
            "Epoch 44/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9789\n",
            "Epoch 44: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0260 - accuracy: 0.9789 - val_loss: 0.7895 - val_accuracy: 0.6445\n",
            "Epoch 45/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9902\n",
            "Epoch 45: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0136 - accuracy: 0.9902 - val_loss: 0.7039 - val_accuracy: 0.7074\n",
            "Epoch 46/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9941\n",
            "Epoch 46: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0064 - accuracy: 0.9941 - val_loss: 0.7382 - val_accuracy: 0.6873\n",
            "Epoch 47/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9920\n",
            "Epoch 47: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0122 - accuracy: 0.9920 - val_loss: 0.7019 - val_accuracy: 0.6878\n",
            "Epoch 48/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9936\n",
            "Epoch 48: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0082 - accuracy: 0.9936 - val_loss: 0.6529 - val_accuracy: 0.6761\n",
            "Epoch 49/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9934\n",
            "Epoch 49: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0093 - accuracy: 0.9934 - val_loss: 0.6846 - val_accuracy: 0.6962\n",
            "Epoch 50/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9947\n",
            "Epoch 50: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0078 - accuracy: 0.9947 - val_loss: 0.7326 - val_accuracy: 0.6901\n",
            "Epoch 51/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9937\n",
            "Epoch 51: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0079 - accuracy: 0.9937 - val_loss: 0.8808 - val_accuracy: 0.6659\n",
            "Epoch 52/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9881\n",
            "Epoch 52: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0150 - accuracy: 0.9881 - val_loss: 0.7770 - val_accuracy: 0.6817\n",
            "Epoch 53/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9933\n",
            "Epoch 53: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0088 - accuracy: 0.9933 - val_loss: 0.7088 - val_accuracy: 0.6794\n",
            "Epoch 54/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9905\n",
            "Epoch 54: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0136 - accuracy: 0.9905 - val_loss: 0.7144 - val_accuracy: 0.6845\n",
            "Epoch 55/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9876\n",
            "Epoch 55: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0172 - accuracy: 0.9876 - val_loss: 0.7246 - val_accuracy: 0.6426\n",
            "Epoch 56/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9830\n",
            "Epoch 56: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0242 - accuracy: 0.9830 - val_loss: 0.6843 - val_accuracy: 0.6873\n",
            "Epoch 57/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9934\n",
            "Epoch 57: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 286ms/step - loss: 0.0102 - accuracy: 0.9934 - val_loss: 0.6645 - val_accuracy: 0.6962\n",
            "Epoch 58/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9915\n",
            "Epoch 58: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0127 - accuracy: 0.9915 - val_loss: 0.6737 - val_accuracy: 0.7027\n",
            "Epoch 59/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9955\n",
            "Epoch 59: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0071 - accuracy: 0.9955 - val_loss: 0.7703 - val_accuracy: 0.7008\n",
            "Epoch 60/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9936\n",
            "Epoch 60: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0097 - accuracy: 0.9936 - val_loss: 0.8713 - val_accuracy: 0.6673\n",
            "Epoch 61/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9944\n",
            "Epoch 61: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 288ms/step - loss: 0.0084 - accuracy: 0.9944 - val_loss: 0.7022 - val_accuracy: 0.6971\n",
            "Epoch 62/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9929\n",
            "Epoch 62: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 288ms/step - loss: 0.0092 - accuracy: 0.9929 - val_loss: 0.8075 - val_accuracy: 0.7064\n",
            "Epoch 63/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9956\n",
            "Epoch 63: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 289ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 0.8924 - val_accuracy: 0.6883\n",
            "Epoch 64/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9941\n",
            "Epoch 64: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 288ms/step - loss: 0.0086 - accuracy: 0.9941 - val_loss: 0.7401 - val_accuracy: 0.6999\n",
            "Epoch 65/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9954\n",
            "Epoch 65: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 291ms/step - loss: 0.0064 - accuracy: 0.9954 - val_loss: 0.8359 - val_accuracy: 0.7195\n",
            "Epoch 66/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9978\n",
            "Epoch 66: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 290ms/step - loss: 0.0032 - accuracy: 0.9978 - val_loss: 0.9011 - val_accuracy: 0.7120\n",
            "Epoch 67/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9991\n",
            "Epoch 67: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 288ms/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 0.9052 - val_accuracy: 0.6990\n",
            "Epoch 68/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9964\n",
            "Epoch 68: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 288ms/step - loss: 0.0054 - accuracy: 0.9964 - val_loss: 0.7915 - val_accuracy: 0.6976\n",
            "Epoch 69/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9929\n",
            "Epoch 69: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 28s 290ms/step - loss: 0.0099 - accuracy: 0.9929 - val_loss: 0.6793 - val_accuracy: 0.7018\n",
            "Epoch 70/70\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9920\n",
            "Epoch 70: val_accuracy did not improve from 0.73672\n",
            "95/95 [==============================] - 27s 288ms/step - loss: 0.0109 - accuracy: 0.9920 - val_loss: 0.7825 - val_accuracy: 0.6589\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compilation du modele en definissant la fonction de perte, l'optimisateur et la valeur afficher durant l'entrainement\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Sauvegarde du modèle ayant le meilleur val_accuracy pendant l'entraînement dans Model.hdf5. \n",
        "modelsPath = \"Model.hdf5\"\n",
        "modelcheckpoint = ModelCheckpoint(filepath=modelsPath,\n",
        "                                  monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "# entrainement du modele\n",
        "classifier = model.fit(X_train, y_train,\n",
        "                       epochs=70, # nombre d' poques\n",
        "                       batch_size=180, # nombre d'images entrain es ensemble\n",
        "                       validation_data=(X_val, y_val), # donn es de validation\n",
        "                       verbose=1, # mets cette valeur   0, si vous voulez ne pas afficher les d tails d'entrainement\n",
        "                       callbacks=[modelcheckpoint], # les fonctions   appeler   la fin de chaque  poque (dans ce cas modelcheckpoint: qui sauvegarde le mod le)\n",
        "                       shuffle=True)# shuffle les images\n",
        "\n",
        "# ==========================================\n",
        "# ========AFFICHAGE DES RESULTATS===========\n",
        "# ==========================================\n",
        "\n",
        "# Plot accuracy over epochs (precision par  poque)\n",
        "print(classifier.history.keys())\n",
        "plt.plot(classifier.history['accuracy'])\n",
        "plt.plot(classifier.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "fig = plt.gcf()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXNM4rxfs4CP",
        "outputId": "41791134-987d-47c8-8b0e-1d119f8bcd9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68/68 [==============================] - 3s 22ms/step\n",
            "Acc= 0.6756255792400371\n",
            "precision= 0.7363134103465595\n",
            "recall= 0.6793327154772938\n",
            "f1= 0.7066763075439865\n",
            "************************\n",
            "67.56255792400371\n",
            "**********\n",
            "32.437442075996294\n",
            "79.64693665628245 20.35306334371755 73.81818181818181 26.181818181818183 56.34920634920635 43.65079365079365 34.12322274881517 65.87677725118483 0.0 100.0\n"
          ]
        }
      ],
      "source": [
        "# Chargement du modèle à partir du fichier spécifié.\n",
        "model_path = \"Model.hdf5\"\n",
        "Classifier : Model = load_model(model_path)\n",
        "\n",
        "\n",
        "#Utilisation du modèle pour effectuer des prédictions sur l'ensemble de test \n",
        "# et Arrondissement des prédictions à la classe la plus probable (0 ou 1 dans le cas d'une classification binaire).\n",
        "predicted_classes = Classifier.predict(X_test)\n",
        "predicted_classes = np.round(predicted_classes)\n",
        "\n",
        "#Calcul et affichage des métriques de performance \n",
        "acc=accuracy_score(y_test, predicted_classes)\n",
        "precision=precision_score(y_test, predicted_classes, average='micro')\n",
        "recall=recall_score(y_test, predicted_classes, average='micro')\n",
        "f1=f1_score(y_test, predicted_classes, average='micro')\n",
        "t=0\n",
        "f=0\n",
        "for i in range(len(predicted_classes)):\n",
        "\n",
        "    if  False in (y_test[i]==predicted_classes[i]):\n",
        "        f=f+1\n",
        "    else:\n",
        "        t=t+1\n",
        "\n",
        "print(\"Acc=\",acc)\n",
        "print(\"precision=\",precision)\n",
        "print(\"recall=\",recall)\n",
        "print(\"f1=\",f1)\n",
        "print(\"************************\")\n",
        "print ((t/len(y_test))*100)\n",
        "print(\"**********\")\n",
        "print ((f/len(y_test))*100)\n",
        "\n",
        "\n",
        "# Cette fonction renvoie les indices des échantillons bien classés pour chaque classe.\n",
        "# Elle prend en parametre x la liste des classes des donnees de test\n",
        "# Elle retourne les listes des indices de chaque classe.\n",
        "def nbMalVal(x):\n",
        "    Norm=[]\n",
        "    Mi=[]\n",
        "    Sttc=[]\n",
        "    Cd=[]\n",
        "    Hyp=[]\n",
        "    for i in range(len(x)):\n",
        "        if x[i][0]==1:\n",
        "            Norm.append(i)\n",
        "        elif x[i][1]==1:\n",
        "            Mi.append(i)\n",
        "        elif x[i][2]==1:\n",
        "            Sttc.append(i)\n",
        "        elif x[i][3]==1:\n",
        "            Cd.append(i)\n",
        "        elif x[i][4]==1:\n",
        "            Hyp.append(i)\n",
        "\n",
        "    return Norm, Mi, Sttc, Cd, Hyp\n",
        "\n",
        "\n",
        "# Cette fonction calcule le pourcentage de prédictions correctes et incorrectes pour une classe donnée.\n",
        "# Elle prend en parametre Norm la liste d'indice d'une classes .\n",
        "# Elle retourne le pourcentages de prédictions correctes et incorrectes.\n",
        "def resultPrct(Norm):\n",
        "  t=0\n",
        "  f=0\n",
        "  for i in range(len(Norm)):\n",
        "    if  False in (y_test[Norm[i]]==predicted_classes[Norm[i]]):\n",
        "        f=f+1\n",
        "    else:\n",
        "        t=t+1\n",
        "  true = ((t/len(Norm))*100)\n",
        "  false= ((f/len(Norm))*100)\n",
        "  return true, false\n",
        "\n",
        "\n",
        "# Affichage du pourcentage de prédictions correctes (true) et incorrectes (false) pour chaque classe.\n",
        "Norm, Mi, Sttc, Cd, Hyp=nbMalVal(y_test)\n",
        "Nt, Nf = resultPrct(Norm)\n",
        "Mt, Mf = resultPrct(Mi)\n",
        "St, Sf = resultPrct(Sttc)\n",
        "Ct, Cf = resultPrct(Cd)\n",
        "Ht, Hf = resultPrct(Hyp)\n",
        "print(Nt, Nf, Mt, Mf, St, Sf, Ct, Cf, Ht,Hf)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
