{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# DIANI Mamoudou Sékou\n",
    "#\n",
    "# Fevrier 2022\n",
    "#==========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupération des données situées dans \"C:/Users/diani/Desktop/Apprntissage_auto/DataPrepa1.csv\"\n",
    "# lecture du CSV et affichage des 5 premieres lignes\n",
    "Pollution_data = pd.read_csv('C:/Users/diani/Desktop/Apprntissage_auto/DataPrepa1.csv', sep = ';', index_col=\"id\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "Pollution_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des donnees avec la normalisation MinMax parce que pour determiner les 7 meilleures features avec chi2\n",
    "# nous devons avoir des valeurs positives\n",
    "features = [\"tLengthOfScreenName\", \"tLengthOfDescriptionInUserProfile\", \"tLongevityOfTheAccount\", \"tNumerOfFollowings\", \"tNumberOfFollowers\", \"tSeriesOfNumberOfFollowings\", \"Following.followers\", \"tNumberOfTweets\", \"tNumberOfTweetsByDays\", \"Tweets.theLongevityOfTheAccount\", \"TweetURL.tNumberOfTweets\", \"tNbMoyenUrlByTweet\", \"UsernameInTweet.tNumberOfTweets\", \"TimeMoyenBet2ConseTweet\", \"ValueOfTimeMaxBet2ConseTweet\"]\n",
    "std_MinMax = preprocessing.MinMaxScaler().fit(Pollution_data[features])\n",
    "normalized_data = std_MinMax.transform(Pollution_data[features])\n",
    "labels = np.array(Pollution_data['Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recherche des 7 meilleures features avec Chi2\n",
    "chi_scores = chi2(normalized_data, labels)\n",
    "\n",
    "\n",
    "# Recupération des donnees et tries du plus imortant au moins important\n",
    "chi_info = []\n",
    "for i in range (len(chi_scores[0])):\n",
    "    chi_info.append([features[i], chi_scores[0][i]])\n",
    "chi_out = sorted(chi_info, key = lambda x : x[1], reverse=True)\n",
    "\n",
    "\n",
    "#Affichage des 7 meilleurs features et de leurs scores chi2 \n",
    "liste_newFeatures_chi2=[]\n",
    "for i in range (7):\n",
    "    x=chi_out[i]\n",
    "    liste_newFeatures_chi2.append(x[0])\n",
    "print(liste_newFeatures_chi2)\n",
    "position=[]\n",
    "for i in range (len(liste_newFeatures_chi2)):\n",
    "    for j in range (len(features)):\n",
    "        if liste_newFeatures_chi2[i] == features[j]:\n",
    "            position.append(j)\n",
    "#print (position)\n",
    "\n",
    "\n",
    "### Elements du dataset à supprimer\n",
    "l=[]\n",
    "a=0\n",
    "for i in range (len(features)):\n",
    "    if i in position:\n",
    "        a=a+1\n",
    "    else:\n",
    "        l.append(i)\n",
    "print (l)\n",
    "\n",
    "\n",
    "\n",
    "# Determination de la nouvelle liste de données\n",
    "newList=[]\n",
    "for i in range(len(normalized_data)):\n",
    "    myArray = np.array(normalized_data[i])\n",
    "    modifiedArray = np.delete(myArray, l)\n",
    "    newList.append(modifiedArray)\n",
    "normalized_data=newList\n",
    "#print (normalized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation des donnees en données d'entrenement et des données de test\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(normalized_data, labels, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction permet de déterminer les metriques de performance \n",
    "# True Positive Rate(TPR), False Positive Rate(FPR) et l'aire sous la courbe ROC (Receiver Operating Characteristic)\n",
    "def TPR_FPR(test_labels, predicted_labels):\n",
    "    cnf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "    #print (cnf_matrix)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_labels, predicted_labels, pos_label=1)\n",
    "    aire = metrics.auc(fpr, tpr)\n",
    "    return (TPR, FPR, aire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_TPR=\"True Positive Rate: \"\n",
    "str_FPR=\"False Positive Rate: \"\n",
    "str_Aire=\"l'aire sous la courbe ROC: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbre de décision: entrainement de l'arbre et prédiction sur les données de test\n",
    "# Et determination de la F-mesure, du FPR, TPR et de l'aire sous la courbe\n",
    "ad_classifier = DecisionTreeClassifier(random_state=42)\n",
    "d_tree1 = ad_classifier.fit(train_features,train_labels)\n",
    "predicted_labels = d_tree1.predict(test_features)\n",
    "\n",
    "tpr, fpr, ad_auc  =TPR_FPR(test_labels, predicted_labels)\n",
    "Val_ad_tpr=tpr[1]\n",
    "Val_ad_fpr=fpr[1]\n",
    "f1 = f1_score(test_labels, predicted_labels, average='binary', pos_label=1)\n",
    "print (str_TPR, Val_ad_tpr)\n",
    "print (str_FPR, Val_ad_fpr)\n",
    "print (str_Aire, ad_auc)\n",
    "f1 = f1_score(test_labels, predicted_labels, average='binary', pos_label=1)\n",
    "print(\"F1-score of decision tree: \", f1)\n",
    "# True Positive Rate:  0.9097206703910614\n",
    "# False Positive Rate:  0.09333333333333334\n",
    "# l'aire sous la courbe ROC:  0.908193668528864\n",
    "# F1-score of decision tree: 0.9145231944288441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest: entrainement et prédiction sur les données de test\n",
    "# Et determination de la F-mesure, du FPR, TPR et de l'aire sous la courbe\n",
    "rnd_forest  = RandomForestClassifier()\n",
    "rnd_forest.fit(train_features,train_labels)\n",
    "predicted_labels = rnd_forest.predict(test_features)\n",
    "\n",
    "tpr, fpr, rf_auc  =TPR_FPR(test_labels, predicted_labels)\n",
    "Val_rf_tpr=tpr[1]\n",
    "Val_rf_fpr=fpr[1]\n",
    "f1 = f1_score(test_labels, predicted_labels, average='binary', pos_label=1)\n",
    "print (str_TPR, Val_rf_tpr)\n",
    "print (str_FPR, Val_rf_fpr)\n",
    "print (str_Aire, rf_auc)\n",
    "f1 = f1_score(test_labels, predicted_labels, average='binary', pos_label=1)\n",
    "print(\"F1-score of random forrest: \", f1)\n",
    "# True Positive Rate:  0.9459217877094972\n",
    "# False Positive Rate:  0.06196078431372549\n",
    "# l'aire sous la courbe ROC:  0.9419805016978857\n",
    "# F1-score of random forrest: 0.9466621938946661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging: entrainement et prédiction sur les données de test\n",
    "# Et determination de la F-mesure, du FPR, TPR et de l'aire sous la courbe\n",
    "bagging = BaggingClassifier()\n",
    "bagging_classifier = bagging.fit(train_features,train_labels)\n",
    "predicted_labels = bagging_classifier.predict(test_features)\n",
    "\n",
    "tpr, fpr, bag_auc  =TPR_FPR(test_labels, predicted_labels)\n",
    "Val_bag_tpr=tpr[1]\n",
    "Val_bag_fpr=fpr[1]\n",
    "print (str_TPR,Val_bag_tpr)\n",
    "print (str_FPR,Val_bag_fpr)\n",
    "print (str_Aire,bag_auc)\n",
    "f1 = f1_score(test_labels, predicted_labels, average='binary', pos_label=1)\n",
    "print(\"F1-score of bagging: \", f1)\n",
    "# True Positive Rate:  0.9289385474860336\n",
    "# False Positive Rate:  0.06248366013071895\n",
    "# l'aire sous la courbe ROC:  0.9332274436776573\n",
    "# F1-score of bagging: 0.9415204678362573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost: entrainement et prédiction sur les données de test\n",
    "# Et determination de la F-mesure, du FPR, TPR et de l'aire sous la courbe\n",
    "adaB = AdaBoostClassifier()\n",
    "adaB_classifier = adaB.fit(train_features,train_labels)\n",
    "predicted_labels = adaB_classifier.predict(test_features)\n",
    "\n",
    "tpr, fpr, adaB_auc  =TPR_FPR(test_labels, predicted_labels)\n",
    "Val_adaB_tpr=tpr[1]\n",
    "Val_adaB_fpr=fpr[1]\n",
    "print (str_TPR,Val_adaB_tpr)\n",
    "print (str_FPR,Val_adaB_fpr)\n",
    "print (str_Aire,adaB_auc)\n",
    "f1 = f1_score(test_labels, predicted_labels, average='binary', pos_label=1)\n",
    "print(\"F1-score of adaBoost: \", f1)\n",
    "# True Positive Rate:  0.9275977653631285\n",
    "# False Positive Rate:  0.06222222222222222\n",
    "# l'aire sous la courbe ROC:  0.9326877715704531\n",
    "# F1-score of adaBoost: 0.9365974729241877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification avec Naive Bayes: entrainement et prédiction sur les données de test\n",
    "# Et determination de la F-mesure, du FPR, TPR et de l'aire sous la courbe\n",
    "bayes_class=GaussianNB()\n",
    "bayes_classifier = bayes_class.fit(train_features,train_labels)\n",
    "predicted_labels = bayes_classifier.predict(test_features)\n",
    "\n",
    "tpr, fpr, nb_auc  =TPR_FPR(test_labels, predicted_labels)\n",
    "Val_nb_tpr=tpr[1]\n",
    "Val_nb_fpr=fpr[1]\n",
    "print (str_TPR,Val_nb_tpr)\n",
    "print (str_FPR,Val_nb_fpr)\n",
    "print (str_Aire,nb_auc)\n",
    "f1 = f1_score(test_labels, predicted_labels, average='binary', pos_label=1)\n",
    "print(\"F1-score of Naive bayes: \", f1)\n",
    "# True Positive Rate:  0.7211173184357542\n",
    "# False Positive Rate:  0.10483660130718954\n",
    "# l'aire sous la courbe ROC:  0.8081403585642823\n",
    "# F1-score of Naive bayes: 0.7964951252622484"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
